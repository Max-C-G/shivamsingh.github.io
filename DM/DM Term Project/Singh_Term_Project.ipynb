{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Quick Ratings Predictor Web-App\n",
    "#### https://review-rating1.azurewebsites.net/\n",
    "\n",
    "- In this notebook we explore a dataset containing reviews of varios board-games and their respective ratings.\n",
    "- With this we build a predictor that would obtain scores from given review\n",
    "\n",
    "\n",
    "## Dataset\n",
    "- The file that was necessary to build this system was -> games_detailed_info.csv\n",
    "- Total number of reviews: 13170073\n",
    "- Total Trainable Reviews (ones with ratings given along with the review): 2637756\n",
    "\n",
    "## Methodology\n",
    "- It is well known that naive bayes performs optimally with text analysis most of the time. It was because of that we decided to pursue building this system with sklearn.MultinomialNB classifier\n",
    "\n",
    "## Cleaning Data\n",
    "- We cleaned each review below by removing unwanted characers and also, removing stopwords from the functions cleanString and removStopWords\n",
    "\n",
    "## Train Test Split\n",
    "- We used 90% of the data to train the dataset and 10% of the data to test it out\n",
    "\n",
    "## NLP Techniques used\n",
    "\n",
    "### 1. Count Vectorizer\n",
    "- We used CountVectorizer which we realized had already used many of the data cleaning methodologies that weren't necessary to be built in the first place. \n",
    "- It Built a sparse matrices of extremely high dimensional data with ease and not consuming too much RAM\n",
    "- We picked 10000 features to build the multinomial model with. \n",
    "\n",
    "### 2. TFIDF\n",
    "- we used sklearn.feature_extraction.text.TfidfTransformer to convert the countvectorized value to tfidf value which would be more impactful in building the model\n",
    "\n",
    "## Issues we faced\n",
    "\n",
    "### 1. Working with High Dimensional Data\n",
    "- One of the biggest issues that was faced was the fact that we tried to build the best 10000 features to build a model, which happened to be extremely slow. Countvectorizer was effective at performing that with much ease. \n",
    "- The blog https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html was very useful in helping in building the model effectively\n",
    "\n",
    "### 2. Azure\n",
    "Setting up Azure had many problems by itself. It wouldn't run the main python file. We identified the problem to be the name of the main python file that was running. It had to be something in the format of \"applications.py\"\n",
    "\n",
    "## Calculations\n",
    "\n",
    "- For any input given the multinomialNB of sklearn can give you the prior probability distributions of the dimensions that are used with clf.predict_proba(tester_tfidf)\n",
    "- Often we noticed that most of the time about 20% of the words from the entire review are utilized in making the decis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from copy import deepcopy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "# https://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas\n",
    "def cleanString(incomingString):\n",
    "    newstring = incomingString.lower()\n",
    "    newstring = newstring.replace(\".\",\"\")\n",
    "    newstring = newstring.replace(\",\",\"\")\n",
    "    newstring = newstring.replace(\"!\",\"\")\n",
    "    newstring = newstring.replace(\"@\",\"\")\n",
    "    newstring = newstring.replace(\"#\",\"\")\n",
    "    newstring = newstring.replace(\"$\",\"\")\n",
    "    newstring = newstring.replace(\"%\",\"\")\n",
    "    newstring = newstring.replace(\"^\",\"\")\n",
    "    newstring = newstring.replace(\"&\",\"and\")\n",
    "    newstring = newstring.replace(\"*\",\"\")\n",
    "    newstring = newstring.replace(\"(\",\"\")\n",
    "    newstring = newstring.replace(\")\",\"\")\n",
    "    newstring = newstring.replace(\"+\",\"\")\n",
    "    newstring = newstring.replace(\"=\",\"\")\n",
    "    newstring = newstring.replace(\"?\",\"\")\n",
    "    newstring = newstring.replace(\"\\'\",\"\")\n",
    "    newstring = newstring.replace(\"\\\"\",\"\")\n",
    "    newstring = newstring.replace(\"{\",\"\")\n",
    "    newstring = newstring.replace(\"}\",\"\")\n",
    "    newstring = newstring.replace(\"[\",\"\")\n",
    "    newstring = newstring.replace(\"]\",\"\")\n",
    "    newstring = newstring.replace(\"<\",\"\")\n",
    "    newstring = newstring.replace(\">\",\"\")\n",
    "    newstring = newstring.replace(\"~\",\"\")\n",
    "    newstring = newstring.replace(\"`\",\"\")\n",
    "    newstring = newstring.replace(\":\",\"\")\n",
    "    newstring = newstring.replace(\";\",\"\")\n",
    "    newstring = newstring.replace(\"|\",\"\")\n",
    "    newstring = newstring.replace(\"\\\\\",\"\")\n",
    "    newstring = newstring.replace(\"/\",\"\")        \n",
    "    return newstring\n",
    "\n",
    "def removeStopWords(incoming):\n",
    "    stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "    all_words = incoming.split(\" \")\n",
    "    for sw in stopwords:\n",
    "        try: all_words.remove(sw)\n",
    "        except: pass\n",
    "    return all_words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input data files are available in the \"./boardgamegeek-reviews/\" directory.\n",
    "\n",
    "# ip = []\n",
    "# for dirname, _, filenames in os.walk('./boardgamegeek-reviews'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "#         ip.append(pd.read_csv(os.path.join(dirname, filename)))\n",
    "# Any results you write to the current directory are saved as output.\n",
    "game_review = pd.read_csv('./boardgamegeek-reviews/bgg-13m-reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game_review = ip[2]\n",
    "# game_detailed_info = ip[0]\n",
    "# game_detail = ip[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13170073\n",
      "2637756\n"
     ]
    }
   ],
   "source": [
    "review_rating_table = pd.DataFrame({'comment': game_review['comment'], 'rating': game_review['rating']})\n",
    "print(len(review_rating_table))\n",
    "review_rating_table = review_rating_table[pd.notna(review_rating_table['comment'])]\n",
    "review_rating_table = review_rating_table.reset_index()\n",
    "review_rating_table = review_rating_table.drop(['index'], axis=1)\n",
    "print(len(review_rating_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_rating_table.loc[2637755,'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round off everything\n",
    "# review_rating_table = review_rating_table.round([1])\n",
    "review_rating_table['rating'] = review_rating_table['rating'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce classes\n",
    "nearest_int = [0,2,2,4,4,6,6,8,8,10,10]\n",
    "for pos, val in enumerate(nearest_int):\n",
    "    review_rating_table.loc[review_rating_table['rating']==pos, 'rating']=val\n",
    "# for pos,val in enumerate(review_rating_table['rating']):\n",
    "#     if pos%10==0:\n",
    "#         print('\\r', 'counter: ', pos, end='')\n",
    "#     review_rating_table.loc[pos, 'rating'] = nearest_int[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Currently, this sits on my list as my favorite...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I know it says how many plays, but many, many ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>i will never tire of this game.. Awesome</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>This is probably the best game I ever played. ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Fantastic game. Got me hooked on games all ove...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2637751</td>\n",
       "      <td>Horrible party game.  I'm dumping this one!</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2637752</td>\n",
       "      <td>Difficult to build anything at all with the in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2637753</td>\n",
       "      <td>Lego created a version of Pictionary, only you...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2637754</td>\n",
       "      <td>This game is very similar to Creationary. It c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2637755</td>\n",
       "      <td>This game was really bad.  Worst that I've pla...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2637756 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   comment  rating\n",
       "0        Currently, this sits on my list as my favorite...      10\n",
       "1        I know it says how many plays, but many, many ...      10\n",
       "2                 i will never tire of this game.. Awesome      10\n",
       "3        This is probably the best game I ever played. ...      10\n",
       "4        Fantastic game. Got me hooked on games all ove...      10\n",
       "...                                                    ...     ...\n",
       "2637751        Horrible party game.  I'm dumping this one!       4\n",
       "2637752  Difficult to build anything at all with the in...       4\n",
       "2637753  Lego created a version of Pictionary, only you...       4\n",
       "2637754  This game is very similar to Creationary. It c...       2\n",
       "2637755  This game was really bad.  Worst that I've pla...       2\n",
       "\n",
       "[2637756 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_rating_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas\n",
    "# Split train and test using pandas\n",
    "msk_train = np.random.rand(len(review_rating_table)) <= 0.9\n",
    "# msk_test = np.random.rand(len(review_rating_table[~msk_train])) <= 0.1\n",
    "review_rating_table_train = review_rating_table[msk_train]\n",
    "review_rating_table_test = review_rating_table[~msk_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = review_rating_table_train['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2374382, 10000)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(min_df = 1, max_features = 10000)\n",
    "X_train_counts = count_vect.fit_transform(review_rating_table_train['comment'])\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vocabulary for web application - count_vect.vocabulary_\n",
    "with open('vocabulary.p', 'wb') as fp:\n",
    "    pickle.dump(count_vect.vocabulary_, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing load vocabulary\n",
    "with open('vocabulary.p', 'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2374382, 10000)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tfidf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with tfidf data of each word in the document wrt all documents, and y value of corresponding doc\n",
    "ytrain = np.around(ytrain).astype('U')\n",
    "clf = MultinomialNB().fit(X_train_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-12.37766266,  -1.94021125,  -3.75901457,  -2.53330428,\n",
       "        -1.238304  ,  -0.76842297])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.class_log_prior_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST DATA \n",
    "- We will run our 10% test data to find the optimal speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take Test, tokenize, tfidf, test\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect_test = CountVectorizer(vocabulary=count_vect.vocabulary_)\n",
    "X_test_counts = count_vect_test.fit_transform(review_rating_table_test['comment'])\n",
    "X_test_counts.shape\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_test_tfidf = tfidf_transformer.fit_transform(X_test_counts)\n",
    "X_test_tfidf.shape\n",
    "ytest = review_rating_table_test['rating']\n",
    "ytest = np.around(ytest).astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5233356367750803"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(prediction==ytest)/len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std deviation\n",
    "prediction = prediction.astype(float)\n",
    "ytest = ytest.astype(float)\n",
    "# ytest\n",
    "# What is the control \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7058651552124853"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Error Root Mean Squared \n",
    "np.sqrt(mse(ytest, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'nb_model_final.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Predicting for a single test case and obtaining the Probability Distribution of the word to be found given the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ['8']\n",
      "Probability:  [[1.09057192e-05 4.19645887e+01 1.82915117e-01 9.24874274e-01\n",
      "  7.60506813e+00 4.93225429e+01]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "newReview = \"Amazing crazy good brilliant excellent mad\"\n",
    "count_vect_test = CountVectorizer(vocabulary=count_vect.vocabulary_)\n",
    "tester_counts = count_vect_test.fit_transform([newReview])\n",
    "tester_counts.shape\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tester_tfidf = tfidf_transformer.fit_transform(tester_counts)\n",
    "tester_tfidf.shape\n",
    "prediction = clf.predict(tester_tfidf)\n",
    "print(\"Prediction:\", prediction)\n",
    "prob = clf.predict_proba(tester_tfidf)\n",
    "prob *= 100\n",
    "prob.tolist()\n",
    "print(\"Probability: \", prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the respective words:  ['Amazing', 'crazy', 'good', 'brilliant', 'excellent', 'mad']\n"
     ]
    }
   ],
   "source": [
    "words = newReview.split(' ')\n",
    "required_words = []\n",
    "count_vector_vocabulary = count_vect.vocabulary_.keys()\n",
    "for word in words:\n",
    "    if(word.lower() in count_vector_vocabulary):\n",
    "        required_words.append(word)\n",
    "print('for the respective words: ', required_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
