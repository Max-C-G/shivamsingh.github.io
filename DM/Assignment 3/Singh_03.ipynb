{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIVE BAYES METHOD \n",
    "### BUILD FROM SCRATCH TO IMPLEMENT SENDIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFE\"RENCES\n",
    "# https://stats.stackexchange.com/questions/323859/why-is-uniform-prior-on-logx-equal-to-1-x-prior-on-x\n",
    "# https://stackoverflow.com/questions/9662346/python-code-to-remove-html-tags-from-a-string\n",
    "# https://streamsql.io/blog/sentiment-analysis\n",
    "# https://medium.com/syncedreview/applying-multinomial-naive-bayes-to-nlp-problems-a-practical-explanation-4f5271768ebf\n",
    "# https://docs.python.org/3/library/glob.html\n",
    "# https://github.com/filipkny/MediumRare/blob/master/NAIVE_BAYES/NaiveBayes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Step\n",
    "- Obtain data, Clean html tags, remove unnecessary symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext\n",
    "\n",
    "def getData(path, extension):\n",
    "    data = []\n",
    "    for filepath in glob.glob(os.path.join(path, extension)):\n",
    "        with open(filepath) as f:\n",
    "            content = f.read()\n",
    "            data.append(content)\n",
    "    return data\n",
    "\n",
    "def preProcess(dataset):\n",
    "    data = [cleanhtml(review).lower().replace(\",\", \"\").replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\")\n",
    "           .replace(\";\", \"\").replace(\":\", \"\").replace(\"*\", \"\")\n",
    "           .replace(\"(\", \"\").replace(\")\", \"\")\n",
    "           .replace(\"/\", \"\").split(' ') for review in dataset]\n",
    "    return data\n",
    "\n",
    "# INVERTED VOCABULARY DEVELOPMENT\n",
    "def vocab_counter(dataset, all_vocabularies = []):\n",
    "    inv_vocab_dict = defaultdict(lambda:0)\n",
    "    for data in dataset:\n",
    "#         print(data)\n",
    "#         Calculating the number of documents the word appears in\n",
    "        words_in_data_pt = []\n",
    "        for word in data:\n",
    "#             print(word)\n",
    "            if word not in words_in_data_pt and word in all_vocabularies:\n",
    "#                 print('imporved')\n",
    "                inv_vocab_dict[word] += 1\n",
    "                words_in_data_pt.append(word)\n",
    "    return inv_vocab_dict\n",
    "\n",
    "# LOW OCCURANCE WORDS REMOVED\n",
    "def vocab_removal(dataset):\n",
    "    all_data = list(dataset.keys())\n",
    "    for data in all_data:\n",
    "        if dataset[data]<5:\n",
    "            del dataset[data]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBTAINING DATA & PREPROCESSING =========================================================================\n",
    "neg_docs = []\n",
    "pos_docs = []\n",
    "train = []\n",
    "\n",
    "train_neg = preProcess(getData('aclImdb/train/neg', '*.txt'))[0:1000]\n",
    "train_pos = preProcess(getData('aclImdb/train/pos', '*.txt'))[0:1000]\n",
    "test_neg = preProcess(getData('aclImdb/test/neg', '*.txt'))[0:1000]\n",
    "test_pos = preProcess(getData('aclImdb/test/pos', '*.txt'))[0:1000]\n",
    "vocab = getData('aclImdb/', '*.vocab')[0].split('\\n')         # All vocabularies in the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INVERTED VOCABULARY DEVELOPMENT & VOCABULARY REMOVAL ===================================================\n",
    "train_neg_vocab_counter = vocab_removal(vocab_counter(train_neg, all_vocabularies=vocab))\n",
    "train_pos_vocab_counter = vocab_removal(vocab_counter(train_pos, all_vocabularies=vocab))\n",
    "train_vocab_counter = vocab_removal(vocab_counter(train_pos+train_neg, all_vocabularies=vocab))\n",
    "test_neg_vocab_counter = vocab_removal(vocab_counter(test_neg, all_vocabularies=vocab))\n",
    "test_pos_vocab_counter = vocab_removal(vocab_counter(test_pos, all_vocabularies=vocab))\n",
    "test_vocab_counter = vocab_removal(vocab_counter(test_pos+test_neg, all_vocabularies=vocab))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALCULATION OF PROBABILITIES\n",
    "- 1000 data points were sampled for the calculations of probability\n",
    "- 200 data points were sampled for testing and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of \"the\" is  0.9915\n",
      "Probability of \"the\", given Positive, is 0.989\n"
     ]
    }
   ],
   "source": [
    "def calculate_prob_occurrence(occurance, data_count, vocab_count, alpha=None):\n",
    "    if alpha==None:\n",
    "        return occurance / data_count\n",
    "    else:\n",
    "        return (occurance + alpha) / (data_count + vocab_count * alpha)\n",
    "\n",
    "\n",
    "# def calculate_prob_pos_or_neg(flag, dataset):\n",
    "def prob_positive(pos_data, data_count):\n",
    "    return len(pos_data)/data_count\n",
    "\n",
    "# CALCULATING CLASSIFIER PROBABILITY OF POSITIVE\n",
    "def probability_of_positive_given_search(search, pos_data, data_count, train_pos_vocab_counter, train_vocab_counter):\n",
    "#     POSITIVE PROBABILITY\n",
    "    probability_of_positive = prob_positive(pos_data, data_count)\n",
    "#     CONDITIONAL PROBABILITY GIVEN POSITIVE\n",
    "    probability_of_search_given_positive = calculate_prob_occurrence(train_pos_vocab_counter[search], len(train_pos), len(train_pos_vocab_counter))\n",
    "#     TOTAL PROBABILITY\n",
    "    probability_of_search = calculate_prob_occurrence(train_vocab_counter[search], len(train_pos), len(train_vocab_counter))\n",
    "    if probability_of_search!=0:\n",
    "        return((probability_of_positive * probability_of_search_given_positive) / probability_of_search)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# These are the required 2 calcuations from the syllabus\n",
    "prob_neg = calculate_prob_occurrence(train_vocab_counter['the'], len(train_neg+train_pos), len(train_vocab_counter))\n",
    "print('Probability of \"the\" is ', prob_neg)\n",
    "\n",
    "\n",
    "prob_the_given_pos = calculate_prob_occurrence(train_pos_vocab_counter['the'], len(train_pos), len(train_pos_vocab_counter))\n",
    "print('Probability of \"the\", given Positive, is', prob_the_given_pos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, data_set, pos_dataset):\n",
    "    correct_count = 0\n",
    "    total_rows = data_set.shape[0]\n",
    "    \n",
    "    for p,d in enumerate(data_set):\n",
    "        if pos_dataset[p] == pred:\n",
    "            correct_count += 1\n",
    "             \n",
    "    return (correct_count / total_rows)\n",
    "\n",
    "\n",
    "def predict_word_review(search, pos_data, data_count, train_pos_vocab_counter, train_vocab_counter):\n",
    "    prob = probability_of_positive_given_search(search, pos_data, data_count, train_pos_vocab_counter, train_vocab_counter)\n",
    "    if prob >= 0.50:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def cross_validation(k, search, data_set, pos_dataset):\n",
    "    k_fold_accuracies = []\n",
    "    increment = (int)(np.array(data_set).shape[0] / k)\n",
    "    for i in range(k):\n",
    "        temp_test_set = np.array(data_set[i*increment:(i+1)*increment])\n",
    "        output = predict_word_review(search, pos_dataset, len(data_set), temp_dev_set_vocab_list, temp_dev_set_vocab_list)\n",
    "        output = np.array(output)\n",
    "        pos_dataset = np.array(pos_dataset)\n",
    "        temp_accuracy = accuracy(output, temp_test_set, pos_dataset)\n",
    "\n",
    "        k_fold_accuracies.append(temp_accuracy)\n",
    "    return (sum(k_fold_accuracies) / len(k_fold_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dev_set_vocab_list = vocab_removal(vocab_counter(dataset, all_vocabularies = []))\n",
    "test_all = test_neg[0:200]+test_pos[0:200]\n",
    "test_all= np.array([[i, 0] for i in test_neg[0:200]]+[[i, 1] for i in test_neg[0:200]])\n",
    "\n",
    "np.random.shuffle(test_all)\n",
    "test = [i[0] for i in test_all]\n",
    "label = [i[1] for i in test_all]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Results\n",
    "- The chance of positive given 'the' is evaluated below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.475"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(5, 'the', test, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
